---
title: "Note on OBI score aggregation"
author: "W.H. Riechelman (NMI)"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
bibliography: [packages.bib, vignettes_references.bib]
vignette: >
  %\VignetteIndexEntry{Note-on-OBI-score-aggregation}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = FALSE,
  collapse = TRUE,
  comment = "#>"
)
options(rmarkdown.html_vignette.check_title = FALSE)
```

# Introduction
The OBIC is a framework that takes a multitude of soil parameters and variables from agricultural fields and ultimately gives a single value expressing the soil quality of that field. To take this multitude of measured, modelled and calulated values to a single value between 0 and 1, three aggregation steps take place as illustrated below.

```{r include score integration image, echo=FALSE, out.width = '85%', out.height = '85%', fig.cap = 'Figure 1. Graphic representation of how measured soil properties are aggregated to scores.'}
# include graphic
knitr::include_graphics('OBIC_score_integratie.png')
```

There is no scientific principle dictating how this aggregation should be done and there are several ways to do the aggregation. For example; averaging, linearly weighted averaging, logistically weighted averaging. The last one is used in OBIC.
This document dives deeper into the three aggregation steps within the framework and will explain  why logistically weighted aggregation is used. We will also explore the two other mentioned methods of aggregation and compare these with the chosen method to illustrate the influence the aggregation method has on the final score and act as a kind of sensitivity analysis.
The aggregation methods will be compared with a mock dataset of a selection of soil functions.
Demonstration of aggregation will be performed using  the dataset `binnenveld`. The dataset contains soil properties from 11 agricultural fields in the surroundings of Wageningen, with different soil texture and land use, and is documented in `?binnenveld`.

```{r load binnenveld}
# load packages
library(OBIC); library(data.table); library(ggplot2); library(patchwork)
# load data
dt <- OBIC::binnenveld[ID==1]
```

# Aggregation
Between calculating soil function scores and aggregating a reformatting step takes place. 
The following things are done during reformatting:

  * it is assessed which indicators are relevant for a field given its soiltype and crop category using the `weight.obic` table.
  * year numbers are assigned from 1 to n with one being the most recent year (used for aggregating over years)
  * a molten data.table is created with all indicators in a single column and soiltype, crop category and year as identifying variables
  * categories are assigned to indicators (chemical, physical, biological, environmental, management)
  * a data.table with the number of indicators per category is made (used in the aggregation of indicators)
  * a correction factor per score is calculated based on the height of the score (used later to give more weight to low scores)
  * soil function scores irrelevant to the land use are set to -999
  
At the beginning of the next step, an indicator data.table is created based on the molten data.table created in the reformatting step. This data.table uses the soil function scores adjusted for their applicability for the soiltype and crop category. 

```{r reformatting code, echo = TRUE, eval=FALSE}
  # Step 3 Reformat dt given weighing per indicator and prepare for aggregation  ------------------
    
    # load weights.obic (set indicator to zero when not applicable)
    w <- as.data.table(OBIC::weight.obic)
    
    # Add years per field
    dt[,year := .I, by = ID]
    
    # Select all indicators used for scoring
    cols <- colnames(dt)[grepl('I_C|I_B|I_P|I_E|I_M|year|crop_cat|SOILT',colnames(dt))]

    # Melt dt and assign main categories for OBI
    dt.melt <- melt(dt[,mget(cols)],
                    id.vars = c('B_SOILTYPE_AGR','crop_category','year'), 
                    variable.name = 'indicator')
    
    # add categories relevant for aggregating
    # C = chemical, P = physics, B = biological, BCS = visual soil assessment
    # indicators not used for integrating: IBCS and IM
    dt.melt[,cat := tstrsplit(indicator,'_',keep = 2)]
    dt.melt[grepl('_BCS$',indicator) & indicator != 'I_BCS', cat := 'IBCS']
    dt.melt[grepl('^I_M_',indicator), cat := 'IM']
    
    # Determine number of indicators per category
    dt.melt.ncat <- dt.melt[year==1 & !cat %in% c('IBCS','IM')][,list(ncat = .N),by='cat']
    
    # add weighing factor to indicator values
    dt.melt <- merge(dt.melt,w[,list(crop_category,indicator,weight_nonpeat,weight_peat)], 
                     by = c('crop_category','indicator'), all.x = TRUE)
    
    # calculate correction factor for indicator values (low values have more impact than high values, a factor 5)
    dt.melt[,cf := cf_ind_importance(value)]
    
    # calculate weighted value for crop category
    dt.melt[,value.w := value]
    dt.melt[grepl('veen',B_SOILTYPE_AGR) & weight_peat < 0,value.w := -999]
    dt.melt[!grepl('veen',B_SOILTYPE_AGR) & weight_nonpeat < 0,value.w := -999]
    
```

## Weighing values
To aggregate scores, the relevant columns and rows are taken from the molten data.table.

```{r echo = TRUE, eval=FALSE}
 # Step 5 Add scores ------------------
    
    # subset dt.melt for relevant columns only
    out.score <-  dt.melt[,list(cat, year, cf, value = value.w)]
  
    # remove indicator categories that are not used for scoring
    out.score <- out.score[!cat %in% c('IBCS','IM','BCS')]
```    

The indicators are weighted using the correction factor calculated previously using `cf_ind_importance()`, giving more weight to lower indicators. This way the lowest indicator, supposedly also to most limiting factor for crop production, becomes more important. Consequently, improving a low score indicator by 0.1 is easier than improving a high scoring indicator by this same amount, making it more worthwhile to invest in the poorest and most limiting indicator.

```{r echo = TRUE, eval=FALSE}    
    # calculate weighted average per indicator category
    out.score <- out.score[,list(value = sum(cf * pmax(0,value) / sum(cf[value >= 0]))), by = list(cat,year)]
  
      # for case that a cat has one indicator or one year and has NA
      out.score[is.na(value), value := -999]
```

## Aggregating over years
Multiple years are used (usually 10) to capture the entire crop rotation (crop rotation in the Netherlands are hardly ever longer than 10 years). When aggregating over years, another correction factor is used to give more weight to recent years. Calculation of the correction factor is done with a logistic function.

These would be the correction factors for a period of eleven years:
```{r output year cf}
  # create data
  y <- 1:11
  cf <- log(12 - pmin(10, y))
  cat(cf)
```

The most recent year carries about `r round(cf[1]/cf[10],digits =1)` the weight of the tenth year. Notice that years ten and eleven have the same correction factor value, the minimum cf value for a year is equal to that of year ten.

More priority (weight) is given to recent years because these are more reflective of the current situation. Additionally, changes in management or soil properties take more immediate effect in subsequent years.

Aggregation of scores over years is done with the following two lines of code. Per indicator an average value is calculated with weights from the correction factor described above.  Side note: The function `obic_field()` has similar lines of code for calculating individual indicators which are given as optional outputs when output is set to 'all' or 'indicators'. Aggregating indicators over years is done in the same fashion.
      
```{r echo = TRUE, eval=FALSE}
            
      # calculate correction factor per year; recent years are more important
      out.score[,cf := log(12 - pmin(10,year))]
  
    # calculate weighted average per indicator category per year
    out.score <- out.score[,list(value = sum(cf * pmax(0,value)/ sum(cf[value >= 0]))), by = cat]
```

This gives us a single score for each of the five indicator themes (chemical, physical, biological, management, and environmental).

## Aggregating to single OBI score
To aggregate the five indicator themes to a single, holistic, OBI-score, they are weighed logistically using the number of soil functions underlying the indicator. The number of soil functions per indicator was retrieved previously with the line `dt.melt.ncat <- dt.melt[year==1 & !cat %in% c('IBCS','IM')][,list(ncat = .N),by='cat']`. Now its merged with our score data.table.

```{r echo = TRUE, eval=FALSE}
      # merge out with number per category
      out.score <- merge(out.score,dt.melt.ncat, by='cat')
```

The correction factor for weighing indicators based on the number of soil functions they are made up of is done like this:

```{r echo = TRUE, eval=FALSE}
      # calculate weighing factor depending on number of indicators
      out.score[,cf := log(ncat + 1)]
```

The weights for indicators with 1 to 10 soil functions are: `r round(log(1:10 +1),2)`. Thus, an indicator based on 10 soil functions affects the total score roughly `r round(log(1:10 +1)[10]/log(1:10 +1)[1],1)` times more than an indicator based on 1 soil function. The idea behind giving more weight to indicators with more underlying soil functions sprouts from the idea that such an indicator is better supported by measurable data or more important. 
Furthermore, by aggregating soil functions to indicators and then to a score rather than directly from soil functions to a score; soil functions from indicators with few underlying soil functions, affect the holistic score more than soil functions in indicators with many soil functions. For example, if there is one biological soil function, its weight in affecting the holistic score is `r round(log(1+1),2)`, while a soil function within a chemical indicator with nine soil functions individually only weighs `r round(log(9+1)/9,2)` (`cf := log(9+1)`). While this example on indicator level, biology only weighs `r round(log(1+1),2)` and chemical `r round(log(9+1),2)`.

After the aggregation there is just a bit of code to format the names of the scores.

```{r echo = TRUE, eval=FALSE}
    # calculated final obi score
    out.score <- rbind(out.score[,list(cat,value)],
                       out.score[,list(cat = "T",value = sum(value * cf / sum(cf)))])
  
    # update element names
    out.score[,cat := paste0('S_',cat,'_OBI_A')]
    out.score[, value := round(value,3)]
```

## Brief recap

* Soil functions with low values gain more weight than ones with heigh values because these soil functions are supposed to be more limiting and this makes it more worthwhile (both in reality as for the OBI score) to invest in improving low scores
* Values from recent years count more than values from long ago. Recent years are more reflective of the current situation and it becomes easier to see the effect of changes in management or soil properties in subsequent years
* Indicators with more underlying soil functions have more weight in determining the total OBI score. This is because these indicators are better understood and supported and may be more important. However, individual soil functions of indicators with few soil functions have more influence on the total OBI score compared to individual soil functions of indicators with many soil functions.

```{r make mock data, eval= TRUE}
# make mock data and calculate scores with different aggregation methods (averaging without weight and averaging with linearly changing weight)
# data like:
# soil_function_value|indicator|group|year|cf_base|cf_noweight|cf_linearweight|score_base|score_noweight|score_linearweight

# visualise differences

# make veldnr
fieldid <- 1

# define standard deviation 
std <- 0.2

# make indicator
inds <- c('I_C_CEC', 'I_C_CU', 'I_C_K', 'I_C_MG', 'I_C_N', 'I_C_P', 'I_C_PH', 'I_C_S', 'I_C_ZN',
          'I_B_DI', 'I_B_SF', 
          'I_E_NGW', 'I_E_NSW',
          'I_P_CEC', 'I_P_CO', 'I_P_CR', 'I_P_DS', 'I_P_DU', 'I_P_SE', 'I_P_WRI', 'I_P_WS')
# inds <- sort(rep(inds, 10))

# make jaar
year <- 1:10

# combine in dt
dt <- data.table(field = sort(rep(fieldid,length(inds)*length(year))),
                 indicator = sort(rep(inds, length(year)*length(fieldid))),
                 year = rep(year, length(inds)*length(fieldid))
                 )

# add category
dt <- dt[,cat := tstrsplit(indicator,'_',keep = 2)]

# iteratively add fields
dto <- data.table(field = NULL, indicator = NULL, year = NULL)
for(i in 1:100){
  dtn <- dt
  dtn <- dtn[,field := i]
  dto <- rbindlist(list(dto, dtn))
}

# dto is a almost ready set of 100 fields, only values and value description need to be added
set.seed(11)

# make baseline
dt1 <- copy(dto)
dt1 <- dt1[,field := field+100-1]
dt1 <- dt1[,treatment := 'baseline']
dt1 <- dt1[,value := rnorm(n = nrow(dt1),mean = 0.7, sd = std)]

# make treatment where c = 0.3
dt2 <- copy(dto)
dt2 <- dt2[,field := field+200-1]
dt2 <- dt2[,treatment := 'low C values']
dt2 <- dt2[cat == 'C',value := rnorm(n = nrow(dt2[cat=='C']),mean = 0.3, sd = std)]
dt2 <- dt2[!cat == 'C',value := rnorm(n = nrow(dt2[!cat=='C']),mean = 0.7, sd = std)]

# make treatment where B = 0.3
dt3 <- copy(dto)
dt3 <- dt3[,field := field+300-1]
dt3 <- dt3[,treatment := 'low B values']
dt3 <- dt3[cat == 'B',value := rnorm(n = nrow(dt3[cat=='B']),mean = 0.3, sd = std)]
dt3 <- dt3[!cat == 'B',value := rnorm(n = nrow(dt3[!cat=='B']),mean = 0.7, sd = std)]

# make treatment where one C indicator = 0
dt4 <- copy(dto)
dt4 <- dt4[,field := field+400-1]
dt4 <- dt4[,treatment := 'one low C']
dt4 <- dt4[indicator == 'I_C_CEC',value := 0]
dt4 <- dt4[!indicator == 'I_C_CEC',value := rnorm(n = nrow(dt4[!indicator == 'I_C_CEC']),mean = 0.7, sd = std)]

# make where one B indicator = 0
dt5 <- copy(dto)
dt5 <- dt5[,field := field+500-1]
dt5 <- dt5[,treatment := 'one low B']
dt5 <- dt5[indicator == 'I_B_DI',value := 0]
dt5 <- dt5[!indicator == 'I_B_DI',value := rnorm(n = nrow(dt5[!indicator == 'I_B_DI']),mean = 0.7, sd = std)]

# make treatment where recent years score low and old years high
dt6 <- copy(dto)
dt6 <- dt6[,field := field+600-1]
dt6 <- dt6[,treatment := 'Recent years low']
dt6 <- dt6[year %in% 1:5, value := rnorm(n = nrow(dt6[year %in% 1:5]), mean = 0.3, sd = std)]
dt6 <- dt6[!year %in% 1:5, value := rnorm(n = nrow(dt6[!year %in% 1:5]), mean = 0.7, sd = std)]

# make treatment where recent years score high and old years low
dt7 <- copy(dto)
dt7 <- dt7[,field := field+700-1]
dt7 <- dt7[,treatment := 'Recent years high']
dt7 <- dt7[!year %in% 1:5, value := rnorm(n = nrow(dt7[!year %in% 1:5]), mean = 0.3, sd = std)]
dt7 <- dt7[year %in% 1:5, value := rnorm(n = nrow(dt7[year %in% 1:5]), mean = 0.7, sd = std)]

# combine all data
dta <- rbindlist(list(dt1, dt2, dt3, dt4, dt5, dt6, dt7))

# make sure all values are between 0 and 1
dta <- dta[value<0, value := 0]
dta <- dta[value>1, value := 1]

```

## Comparison with other aggregation methods
### Data description
To compare aggregation methods we have made a data.table with mock data similar to a data.table in the obic_field function just before aggregating scores. We will compare the aggregation methods with seven scenarios or treatments. Each treatment has a 100 replicates whose soil function values are randomly drawn from a normal distribution with a standard deviation of `r std[1]`. The mean of the distributions depends on the scenario. On rare occasion a value may fall slightly outside the range 0:1, in such cases the values are overwritten to be 0 or 1. 

1. **Baseline** all mean value are 0.7
2. **Low C values** means of Chemical functions are 0.3, functions in other indicators are 0.7
3. **Low B values** means of Biological functions are 0.3, functions in other indicators are 0.7
4. **One low C value** one chemical soil function value is set to 0, all other values are generated as in the baseline
5. **One low B value** one biological soil function value is set to 0, all other values are generated as in the baseline
6. **Recent years low** mean values of the most recent five years are 0.3, while the five years before that have mean values of 0.7
7. **Recent years high** mean values of the most recent five years are 0.7, while the five years before that have mean values of 0.3

### Correction factors
In comparing the methods of aggregation we will use three methods to determine a correction factor (cf) for each measurement/value: 

* logarithmically
* linearly
* no correction (averaging all values, cf = 1)

The log and linear cf's are illustrated in Figure 2 in the range that they operate. **Value** is the correction factor for the measured soil function values, these range from 0 to 1. **year** is the correction factor for the year a measurement is from, 1 being the most recent year, 10 being ten years earlier. **ncat** is the correction for the number of soil functions within an indicator, for Chemical this typically is `r length(grep('I_C_', names(obic_field_dt(binnenveld, output = 'indicators'))))`
The no correction method is not presented in Figure 2 as it would be a horizontal line with an arbitrary value.

```{r plot mock cf, fig.width = 7, fig.height = 4,fig.fullwidth = TRUE, fig.cap = 'Figure 2. Correction factors calculated with linear or logarithmic methods per aggregation step.'}
# plot correction factors
pdtlog <- data.table(x = c(seq(0,1,0.1),rep(0:10,2)),
                  cf_type = c(rep('value',11),rep('year',11), rep('ncat', 11)))
# calc cf's log
pdtlog <- pdtlog[cf_type == 'value', cf := OBIC::cf_ind_importance(x)]
pdtlog <- pdtlog[cf_type == 'year', cf := log(12 - pmin(10,x))]
pdtlog <- pdtlog[cf_type == 'ncat', cf := log(x + 1)]
pdtlog$cf_method <- 'log'

# calc cf's linear
pdtlin <- data.table(x = c(seq(0,1,0.1),rep(0:10,2)),
                  cf_type = c(rep('value',11),rep('year',11), rep('ncat', 11)))
pdtlin <- pdtlin[cf_type == 'value', cf := 5-4.17*x]
pdtlin <- pdtlin[cf_type == 'year', cf := 2.59-0.19*x]
pdtlin <- pdtlin[cf_type == 'ncat', cf := x*log(11)/10]
pdtlin$cf_method <- 'linear'

# combine
pdt <- rbindlist(list(pdtlog, pdtlin))
# format pdt
pdt <- pdt[,cf_type := factor(cf_type, levels = c('value', 'year', 'ncat'))]

# plot
gg <- ggplot(pdt, aes(x = x, y = cf, color = cf_method, group = cf_type))+
  geom_point() +
  theme_bw() + facet_wrap(~cf_type, ncol = 3, scales = 'free') + scale_colour_viridis_d()+
  xlab('') + ylab('cf (weight)')
for(i in 1:uniqueN(pdt$cf_method)){
  gg <- gg + geom_line(data = pdt[cf_method == unique(pdt$cf_method)[i]], color = c('#FDE725FF', '#440154FF')[i])
}

# plot gg
gg
```

```{r calc correction factors}
# Use three ways to calc correction factors (giving weight to each value), log (standard in OBIC), lin (linearly increasing/decreasing), non (everything has the same weight)

# value correction factors ======
dt <- copy(dta)

# log cf
dt <- dt[,log := OBIC::cf_ind_importance(value)]

# lin cf
dt <- dt[,lin := 5-4.17*value]

# non cf
dt <- dt[,non := 1]

# melt dt by cf method
dt <- melt(dt, measure.vars = c('log', 'lin', 'non'), value.name = 'v_cf', variable.name = 'cf_method')


# calculate cf for years =====
# log cf
dt <- dt[cf_method == 'log',y_cf := log(12 - pmin(10,year))]

# lin cf
dt <- dt[cf_method == 'lin',y_cf := 2.59-0.19*value]

# non cf
dt <- dt[cf_method == 'non',y_cf := 1]


# calculate cf for cat ====
ncat <- unique(dt[,.(indicator, cat)])
for(c in unique(ncat$cat)){
  n <- nrow(ncat[cat == c])
  ncat <- ncat[cat == c,ncat := n]
}
dt <- merge(dt, ncat, by = c('indicator', 'cat'))

# log cf
dt <- dt[cf_method == 'log',c_cf := log(ncat + 1)]

# log lin
dt <- dt[cf_method == 'lin',c_cf := ncat*log(10 + 1)/10]

# non cf
dt <- dt[cf_method == 'non',c_cf := 1]

```

```{r aggregate scores}
# # get col group vectos
# idcols <- c("indicator", "cat", "field", "year","treatment", "value")
# logcols <- names(dt)[grepl('log$', names(dt))]
# lincols <- names(dt)[grepl('lin$', names(dt))]
# noncols <- names(dt)[grepl('non$', names(dt))]
# 

# calculate weighted value per category and year
dt <- dt[,w.value := sum(v_cf* pmax(0,value) / sum(v_cf[value >= 0])), by = .(field, cf_method, cat, year)]

# calculated weighted average value per category (so mean over years)
dt <- dt[,wy.value := sum(y_cf * pmax(0, w.value) / sum(y_cf[w.value >= 0])), by = .(field, cf_method, cat)] # scores per category

# calculate total obi score
dt <- dt[,S_T := sum(wy.value * c_cf / sum(c_cf)), by = .(field, cf_method)]

# calculate total obi score if not aggregated by cat
dt <- dt[, nocat.value := sum(v_cf* pmax(0,value) / sum(v_cf[value >= 0])), by = .(field, cf_method, year)]
dt <- dt[, S_T_nocat := sum(y_cf * pmax(0, nocat.value) / sum(y_cf[nocat.value >= 0])), by = .(field, cf_method)]

# select data for scores
dts <- unique(dt[,.(field, indicator,cat, wy.value, S_T ,treatment, cf_method, S_T_nocat)])

# reshape dts so total scores are in same column as cat scores (with T being a cat)
dts1 <- unique(dts[,.(field, cat, wy.value, treatment, cf_method)])
dts2 <- unique(dts[,.(field, S_T, treatment, cf_method)])
dts3 <- unique(dts[,.(field, S_T_nocat, treatment, cf_method)])

# rename  cols
setnames(dts1, 'wy.value', 'score')
setnames(dts2, 'S_T', 'score')
setnames(dts3, 'S_T_nocat', 'score')
# add cat column to dts2
dts2$cat <- 'T'
dts3$cat <- 'Tnocat'

# bind scores dt's
dt <- rbindlist(list(dts1, dts2, dts3), use.names = TRUE)

# update element names
dt[,cat := paste0('S_',cat,'_OBI_A')]
dt[, score := round(score,3)]

# factorise cat and cf_method
dt <- dt[, cat := factor(cat, levels = c('S_T_OBI_A', 'S_C_OBI_A', 'S_P_OBI_A', 'S_B_OBI_A', 'S_E_OBI_A',  "S_Tnocat_OBI_A"))]
dt <- dt[, cf_method := factor(cf_method, levels = c('log', 'lin', 'non'))]

```

```{r plot baselines scores, fig.width = 7, fig.height = 12,fig.fullwidth = TRUE, fig.cap = 'Figure 3. Total OBI score boxplots per aggregation method for each scenario.'}
# plot
ggplot(dt[cat == 'S_T_OBI_A'], aes(x = score, y = cf_method)) +
  geom_boxplot() +
  theme_bw() + scale_colour_viridis_d() + scale_y_discrete(limits = rev) +
  coord_cartesian(xlim = c(0,1)) +
  facet_wrap(~treatment, ncol = 1)

```


```{r plot original values, fig.width = 7, fig.height = 20,fig.fullwidth = TRUE, fig.cap = 'Figure 4. Distribution of "measured" values of each soil function per scenario.'}
# factorise dta cat levels
dta <- dta[, cat := factor(cat, levels = c('C', 'P', 'B', 'E'))]
dta <- dta[, indicator := factor(indicator, levels = c("I_C_CEC","I_C_CU", "I_C_K",  "I_C_MG", "I_C_N",  "I_C_P",  "I_C_PH", "I_C_S",  "I_C_ZN", 
                                                       "I_P_CR", "I_P_DS", "I_P_DU", "I_P_SE", "I_P_WRI", "I_P_WS","I_P_CEC","I_P_CO", 
                                                       "I_B_DI", "I_B_SF", "I_E_NGW","I_E_NSW"))]

# plot
ggplot(dta, aes(x = value, y = indicator, color = cat))+
  geom_boxplot() +
  theme_bw() + coord_cartesian(xlim = c(0,1)) + scale_y_discrete(limits = rev)+
  facet_wrap(~treatment, ncol = 1)

```

In Figure 3 one can see that with logarithmic evaluation, scores become responsive to changes in recent years while this is not the case for linear or no aggregation. 

```{r plot scores with and without cat, fig.width = 7, fig.height = 12,fig.fullwidth = TRUE, fig.cap = 'Figure 5. Scores when categories are ignored during aggregation (S_Tnocat_OBI_A) and regular aggregation (S_T_OBI_A).'}

gg3 <- ggplot(dt[cat %in% c('S_T_OBI_A', 'S_Tnocat_OBI_A')], aes(x = score, y = cf_method, fill = cat)) +
  geom_boxplot() +
  theme_bw() + scale_fill_viridis_d() + scale_y_discrete(limits = rev) +
  coord_cartesian(xlim = c(0,1)) +
  facet_wrap(~treatment, ncol = 1) #+ geom_boxplot(data = dt[cat == 'S_Tnocat_OBI_A'], mapping = aes(fill = 'blue')) 
gg3 
```


```{r, eval=FALSE}
  obic_field(B_SOILTYPE_AGR =  dt$B_SOILTYPE_AGR, B_GWL_CLASS =  dt$B_GWL_CLASS,
             B_SC_WENR = dt$B_SC_WENR, B_HELP_WENR = dt$B_HELP_WENR, B_AER_CBS = dt$B_AER_CBS,
             B_LU_BRP = dt$B_LU_BRP, A_SOM_LOI = dt$A_SOM_LOI, A_SAND_MI = dt$A_SAND_MI,
             A_SILT_MI = dt$A_SILT_MI, A_CLAY_MI = dt$A_CLAY_MI, A_PH_CC = dt$A_PH_CC,
             A_CACO3_IF = dt$A_CACO3_IF, A_N_RT = dt$A_N_RT, A_CN_FR = dt$A_CN_FR,
             A_COM_FR = dt$A_COM_FR, A_S_RT = dt$A_S_RT, A_N_PMN = dt$A_N_PMN,
             A_P_AL = dt$A_P_AL, A_P_CC = dt$A_P_CC, A_P_WA = dt$A_P_WA, A_CEC_CO = dt$A_CEC_CO,
             A_CA_CO_PO = dt$A_CA_CO_PO, A_MG_CO_PO = dt$A_MG_CO_PO, A_K_CO_PO = dt$A_K_CO_PO,
             A_K_CC = dt$A_K_CC, A_MG_CC = dt$A_MG_CC, A_MN_CC = dt$A_MN_CC,
             A_ZN_CC = dt$A_ZN_CC, A_CU_CC = dt$A_CU_CC, output = 'obic_score')
```

## Aggregation in other soil quality assesment frameworks
e.g. (van Wijnen et. al. 2012 and  Rutgers et. al. 2012) or Moebius-Clune 2016